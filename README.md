# ASR Transformer

This project is originally forked from https://github.com/chqiwang/transformer and we change it into ASR task. We compared five modeling units on Mandarin Chinese ASR tasks on HKUST datasets by sequence-to-sequence attention-based model with the Transformer, including CI-phonemes, syllables, words, sub-words and characters.

Run steps:
1)config your *.yaml; 2)python train.py; 3)python evaluate.py

Source Code for paper:
Syllable-Based Sequence-to-Sequence Speech Recognition with Transformer in Mandarin Chinese.pdf
A Comparison of Modeling Units in Sequence-to-Sequence Speech Recognition with the Transformer on Mandarin Chinese.pdf

Contact
Raise an issue on github or email to zhoushiyu2013@ia.ac.cn.
